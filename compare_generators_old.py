#!/usr/bin/env python
"""
é‡å­vså¤å…¸ç”Ÿæˆå™¨æ€§èƒ½å¯¹æ¯”åˆ†æè„šæœ¬
ç”¨äºæ¯”è¾ƒä¸åŒç”Ÿæˆå™¨ç±»å‹çš„æ€§èƒ½æŒ‡æ ‡
"""

import mlflow
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')

def get_experiment_runs(experiment_name: str) -> pd.DataFrame:
    """è·å–å®éªŒçš„æ‰€æœ‰è¿è¡Œè®°å½•"""
    client = mlflow.tracking.MlflowClient()
    experiment = client.get_experiment_by_name(experiment_name)
    
    if experiment is None:
        print(f"å®éªŒ '{experiment_name}' ä¸å­˜åœ¨")
        return pd.DataFrame()
    
    runs = client.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["attribute.start_time desc"]
    )
    
    # æå–è¿è¡Œæ•°æ®
    data = []
    for run in runs:
        run_data = {
            'run_id': run.info.run_id,
            'generator_type': run.data.params.get('generator_type', 'unknown'),
            'status': run.info.status,
            'start_time': run.info.start_time,
            'end_time': run.info.end_time,
            'duration_seconds': (run.info.end_time - run.info.start_time) / 1000 if run.info.end_time else None
        }
        
        # æ·»åŠ å…³é”®æŒ‡æ ‡
        metrics_to_track = [
            'ValidationStep_FakeData_KLDivergence',
            'ValidationStep_FakeData_LogLikelihood', 
            'ValidationStep_FakeData_IsPositive',
            'ValidationStep_FakeData_WassersteinDistance',
            'ValidationStep_FakeData_MMDDistance',
            'train_loss_step',
            'd_loss',
            'g_loss'
        ]
        
        for metric in metrics_to_track:
            value = run.data.metrics.get(metric, None)
            # ç¡®ä¿æ•°å€¼æŒ‡æ ‡ä¸ºfloatç±»å‹
            if value is not None:
                try:
                    run_data[metric] = float(value)
                except (ValueError, TypeError):
                    run_data[metric] = None
            else:
                run_data[metric] = None
        
        data.append(run_data)
    
    df = pd.DataFrame(data)
    
    # ç¡®ä¿æ•°å€¼åˆ—çš„ç±»å‹æ­£ç¡®
    numeric_columns = [
        'ValidationStep_FakeData_KLDivergence',
        'ValidationStep_FakeData_LogLikelihood', 
        'ValidationStep_FakeData_IsPositive',
        'ValidationStep_FakeData_WassersteinDistance',
        'ValidationStep_FakeData_MMDDistance',
        'train_loss_step',
        'd_loss',
        'g_loss',
        'duration_seconds'
    ]
    
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    return df

def analyze_convergence(client, run_id: str) -> Dict:
    """åˆ†æå•ä¸ªè¿è¡Œçš„æ”¶æ•›ç‰¹æ€§"""
    # è·å–å†å²æŒ‡æ ‡
    metric_history = client.get_metric_history(run_id, "ValidationStep_FakeData_KLDivergence")
    
    if not metric_history:
        return {}
    
    epochs = [m.step for m in metric_history]
    values = [m.value for m in metric_history]
    
    # è®¡ç®—æ”¶æ•›æŒ‡æ ‡
    convergence_info = {
        'final_value': values[-1] if values else None,
        'best_value': min(values) if values else None,
        'epochs_to_best': epochs[np.argmin(values)] if values else None,
        'improvement_rate': (values[0] - values[-1]) / len(values) if len(values) > 1 else 0,
        'stability': np.std(values[-5:]) if len(values) >= 5 else None
    }
    
    return convergence_info

def compare_generators(experiment_name: str = None):
    """ä¸»å¯¹æ¯”å‡½æ•°"""
    print("=" * 80)
    print("é‡å­ vs å¤å…¸ç”Ÿæˆå™¨æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    # è·å–è¿è¡Œæ•°æ®
    if experiment_name is None:
        # è‡ªåŠ¨å‘ç°æ‰€æœ‰ç›¸å…³å®éªŒ
        client = mlflow.tracking.MlflowClient()
        experiments = client.search_experiments()
        
        # å¯»æ‰¾åŒ…å«å¤å…¸å’Œé‡å­å®éªŒçš„æ•°æ®
        all_runs = []
        for exp in experiments:
            if any(keyword in exp.name.lower() for keyword in ['gaussgan', 'classical', 'quantum']):
                print(f"æ£€æŸ¥å®éªŒ: {exp.name}")
                exp_df = get_experiment_runs(exp.name)
                if not exp_df.empty:
                    all_runs.append(exp_df)
        
        if all_runs:
            df = pd.concat(all_runs, ignore_index=True)
        else:
            df = pd.DataFrame()
    else:
        df = get_experiment_runs(experiment_name)
    
    if df.empty:
        print("æ²¡æœ‰æ‰¾åˆ°å®éªŒæ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå®éªŒ")
        return
    
    # æŒ‰ç”Ÿæˆå™¨ç±»å‹åˆ†ç»„
    generator_types = df['generator_type'].unique()
    print(f"\næ‰¾åˆ° {len(generator_types)} ç§ç”Ÿæˆå™¨ç±»å‹: {list(generator_types)}")
    print(f"æ€»å…± {len(df)} æ¬¡è¿è¡Œ\n")
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    comparison_results = []
    client = mlflow.tracking.MlflowClient()
    
    for gen_type in generator_types:
        gen_runs = df[df['generator_type'] == gen_type]
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        result = {
            'ç”Ÿæˆå™¨ç±»å‹': gen_type,
            'è¿è¡Œæ¬¡æ•°': len(gen_runs),
            'å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)': gen_runs['duration_seconds'].mean(),
            'KLæ•£åº¦(å¹³å‡)': gen_runs['ValidationStep_FakeData_KLDivergence'].mean(),
            'KLæ•£åº¦(æœ€ä½³)': gen_runs['ValidationStep_FakeData_KLDivergence'].min(),
            'å¯¹æ•°ä¼¼ç„¶(å¹³å‡)': gen_runs['ValidationStep_FakeData_LogLikelihood'].mean(),
            'Wassersteinè·ç¦»': gen_runs['ValidationStep_FakeData_WassersteinDistance'].mean(),
            'MMDè·ç¦»': gen_runs['ValidationStep_FakeData_MMDDistance'].mean(),
        }
        
        # è·å–æœ€ä½³è¿è¡Œçš„æ”¶æ•›ä¿¡æ¯
        valid_runs = gen_runs.dropna(subset=['ValidationStep_FakeData_KLDivergence'])
        if not valid_runs.empty:
            best_run = valid_runs.nsmallest(1, 'ValidationStep_FakeData_KLDivergence').iloc[0]
            convergence = analyze_convergence(client, best_run['run_id'])
            result.update({
                'æ”¶æ•›epochs': convergence.get('epochs_to_best', 'N/A'),
                'æ”¹è¿›ç‡': convergence.get('improvement_rate', 'N/A'),
                'æœ€ç»ˆç¨³å®šæ€§': convergence.get('stability', 'N/A')
            })
        else:
            result.update({
                'æ”¶æ•›epochs': 'N/A',
                'æ”¹è¿›ç‡': 'N/A',
                'æœ€ç»ˆç¨³å®šæ€§': 'N/A'
            })
        
        comparison_results.append(result)
    
    # åˆ›å»ºå¯¹æ¯”DataFrame
    comparison_df = pd.DataFrame(comparison_results)
    
    # æ‰“å°è¯¦ç»†å¯¹æ¯”
    print("\n" + "="*80)
    print("æ€§èƒ½å¯¹æ¯”ç»“æœ")
    print("="*80)
    
    # è®­ç»ƒæ•ˆç‡å¯¹æ¯”
    print("\nğŸ“Š è®­ç»ƒæ•ˆç‡å¯¹æ¯”:")
    print("-" * 40)
    for _, row in comparison_df.iterrows():
        print(f"{row['ç”Ÿæˆå™¨ç±»å‹']:20s}: {row['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)']:.2f} ç§’")
    
    # ç”Ÿæˆè´¨é‡å¯¹æ¯”
    print("\nğŸ“ˆ ç”Ÿæˆè´¨é‡å¯¹æ¯” (è¶Šä½è¶Šå¥½):")
    print("-" * 40)
    print(f"{'æŒ‡æ ‡':<20} {'å¤å…¸ç”Ÿæˆå™¨':<15} {'é‡å­ç”Ÿæˆå™¨':<15} {'å·®å¼‚':<15}")
    print("-" * 65)
    
    metrics_to_compare = ['KLæ•£åº¦(æœ€ä½³)', 'Wassersteinè·ç¦»', 'MMDè·ç¦»']
    
    for metric in metrics_to_compare:
        classical_val = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('classical')][metric].values
        quantum_val = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('quantum')][metric].values
        
        if len(classical_val) > 0 and len(quantum_val) > 0:
            c_val = classical_val[0]
            q_val = quantum_val[0]
            if pd.notna(c_val) and pd.notna(q_val):
                diff = ((q_val - c_val) / c_val * 100) if c_val != 0 else 0
                print(f"{metric:<20} {c_val:<15.4f} {q_val:<15.4f} {diff:+.1f}%")
    
    # æ”¶æ•›é€Ÿåº¦å¯¹æ¯”
    print("\nâš¡ æ”¶æ•›é€Ÿåº¦å¯¹æ¯”:")
    print("-" * 40)
    for _, row in comparison_df.iterrows():
        print(f"{row['ç”Ÿæˆå™¨ç±»å‹']:20s}: {row['æ”¶æ•›epochs']} epochs")
    
    # æ€§èƒ½æ¯”ç‡è®¡ç®—
    print("\n" + "="*80)
    print("æ€§èƒ½æ¯”ç‡åˆ†æ")
    print("="*80)
    
    classical_rows = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('classical')]
    quantum_rows = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('quantum')]
    
    if not classical_rows.empty and not quantum_rows.empty:
        # è®¡ç®—å¹³å‡æ—¶é—´æ¯”ç‡
        c_time_avg = classical_rows['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].mean()
        q_time_avg = quantum_rows['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].mean()
        time_ratio = q_time_avg / c_time_avg
        print(f"\nâ±ï¸  å¹³å‡æ—¶é—´æ¯”ç‡: é‡å­ç”Ÿæˆå™¨æ¯”å¤å…¸ç”Ÿæˆå™¨æ…¢ {time_ratio:.1f}x")
        
        # è¯¦ç»†æ—¶é—´åˆ†æ
        print(f"   å¤å…¸ç”Ÿæˆå™¨å¹³å‡è®­ç»ƒæ—¶é—´: {c_time_avg:.1f} ç§’")
        print(f"   é‡å­ç”Ÿæˆå™¨å¹³å‡è®­ç»ƒæ—¶é—´: {q_time_avg:.1f} ç§’")
    
    # æ•°æ®è´¨é‡åˆ†æ
    print(f"\nğŸ“Š æ•°æ®è´¨é‡åˆ†æ:")
    print("-" * 40)
    for gen_type in comparison_df['ç”Ÿæˆå™¨ç±»å‹']:
        row = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'] == gen_type].iloc[0]
        runs = row['è¿è¡Œæ¬¡æ•°']
        kl_avg = row['KLæ•£åº¦(å¹³å‡)']
        kl_best = row['KLæ•£åº¦(æœ€ä½³)']
        if pd.notna(kl_avg) and pd.notna(kl_best):
            print(f"{gen_type:20s}: {runs}æ¬¡è¿è¡Œ, KLæ•£åº¦ {kl_best:.3f} (æœ€ä½³) / {kl_avg:.3f} (å¹³å‡)")
    
    # åˆ›å»ºå¯è§†åŒ–
    create_visualization(comparison_df)
    
    # ä¿å­˜ç»“æœ
    comparison_df.to_csv('generator_comparison_results.csv', index=False)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: generator_comparison_results.csv")
    
    return comparison_df

def create_visualization(comparison_df: pd.DataFrame):
    """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # ç¡®ä¿axesæ€»æ˜¯2Dæ•°ç»„ï¼Œå³ä½¿åªæœ‰ä¸€è¡Œæˆ–ä¸€åˆ—
    if axes.ndim == 1:
        axes = axes.reshape(-1, 1)
    
    # è®­ç»ƒæ—¶é—´å¯¹æ¯”
    ax = axes[0][0]
    valid_time_data = comparison_df.dropna(subset=['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'])
    if not valid_time_data.empty:
        ax.bar(valid_time_data['ç”Ÿæˆå™¨ç±»å‹'], valid_time_data['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'])
        ax.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
        ax.set_ylabel('æ—¶é—´ (ç§’)')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    else:
        ax.text(0.5, 0.5, 'æ— å¯ç”¨æ•°æ®', ha='center', va='center', transform=ax.transAxes)
        ax.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
    
    # KLæ•£åº¦å¯¹æ¯”
    ax = axes[0][1]
    valid_kl_data = comparison_df.dropna(subset=['KLæ•£åº¦(æœ€ä½³)'])
    if not valid_kl_data.empty:
        ax.bar(valid_kl_data['ç”Ÿæˆå™¨ç±»å‹'], valid_kl_data['KLæ•£åº¦(æœ€ä½³)'])
        ax.set_title('KLæ•£åº¦å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        ax.set_ylabel('KLæ•£åº¦')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    else:
        ax.text(0.5, 0.5, 'æ— å¯ç”¨æ•°æ®', ha='center', va='center', transform=ax.transAxes)
        ax.set_title('KLæ•£åº¦å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
    
    # Wassersteinè·ç¦»å¯¹æ¯”
    ax = axes[1][0]
    valid_ws_data = comparison_df.dropna(subset=['Wassersteinè·ç¦»'])
    if not valid_ws_data.empty:
        ax.bar(valid_ws_data['ç”Ÿæˆå™¨ç±»å‹'], valid_ws_data['Wassersteinè·ç¦»'])
        ax.set_title('Wassersteinè·ç¦»å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        ax.set_ylabel('Wassersteinè·ç¦»')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    else:
        ax.text(0.5, 0.5, 'æ— å¯ç”¨æ•°æ®', ha='center', va='center', transform=ax.transAxes)
        ax.set_title('Wassersteinè·ç¦»å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
    
    # MMDè·ç¦»å¯¹æ¯”
    ax = axes[1][1]
    valid_mmd_data = comparison_df.dropna(subset=['MMDè·ç¦»'])
    if not valid_mmd_data.empty:
        ax.bar(valid_mmd_data['ç”Ÿæˆå™¨ç±»å‹'], valid_mmd_data['MMDè·ç¦»'])
        ax.set_title('MMDè·ç¦»å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        ax.set_ylabel('MMDè·ç¦»')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    else:
        ax.text(0.5, 0.5, 'æ— å¯ç”¨æ•°æ®', ha='center', va='center', transform=ax.transAxes)
        ax.set_title('MMDè·ç¦»å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
    
    plt.tight_layout()
    plt.savefig('generator_comparison_plots.png', dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: generator_comparison_plots.png")

if __name__ == "__main__":
    # è¿è¡Œå¯¹æ¯”åˆ†æ
    results = compare_generators()
    
    if results is not None and not results.empty:
        print("\n" + "="*80)
        print("ğŸ¯ å…³é”®å‘ç°:")
        print("="*80)
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        classical_rows = results[results['ç”Ÿæˆå™¨ç±»å‹'].str.contains('classical')]
        quantum_rows = results[results['ç”Ÿæˆå™¨ç±»å‹'].str.contains('quantum')]
        
        if not classical_rows.empty and not quantum_rows.empty:
            c_kl = classical_rows['KLæ•£åº¦(æœ€ä½³)'].values[0]
            q_kl = quantum_rows['KLæ•£åº¦(æœ€ä½³)'].values[0]
            c_time = classical_rows['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].values[0]
            q_time = quantum_rows['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].values[0]
            
            print(f"\n1. é‡å­ç”Ÿæˆå™¨è®­ç»ƒæ—¶é—´æ˜¯å¤å…¸ç”Ÿæˆå™¨çš„ {q_time/c_time:.1f} å€")
            
            if pd.notna(c_kl) and pd.notna(q_kl):
                if q_kl < c_kl:
                    print(f"2. é‡å­ç”Ÿæˆå™¨çš„KLæ•£åº¦æ¯”å¤å…¸ç”Ÿæˆå™¨ä½ {(c_kl-q_kl)/c_kl*100:.1f}% (æ›´å¥½)")
                else:
                    print(f"2. é‡å­ç”Ÿæˆå™¨çš„KLæ•£åº¦æ¯”å¤å…¸ç”Ÿæˆå™¨é«˜ {(q_kl-c_kl)/c_kl*100:.1f}% (æ›´å·®)")
            
            print("\nè¿™äº›æ•°å€¼åŒ–ç»“æœç›´æ¥å›ç­”äº†Aleçš„é—®é¢˜ï¼š")
            print("âœ… æˆ‘ä»¬ç°åœ¨å¯ä»¥ç²¾ç¡®æµ‹é‡å¤å…¸å’Œé‡å­ç”Ÿæˆå™¨çš„æ€§èƒ½å·®å¼‚")
            print("âœ… ä¸ä»…æœ‰å¯è§†åŒ–å¯¹æ¯”ï¼Œè¿˜æœ‰å…·ä½“çš„æ•°å€¼æŒ‡æ ‡")
            
            print("\n" + "="*80)
            print("ğŸ” æ·±å…¥åˆ†æ")
            print("="*80)
            
            # åˆ†æç»“æœçš„å¯é æ€§
            c_runs = classical_rows['è¿è¡Œæ¬¡æ•°'].sum()
            q_runs = quantum_rows['è¿è¡Œæ¬¡æ•°'].sum()
            print(f"\næ•°æ®æ ·æœ¬å¤§å°:")
            print(f"- å¤å…¸ç”Ÿæˆå™¨: {c_runs} æ¬¡è¿è¡Œ")
            print(f"- é‡å­ç”Ÿæˆå™¨: {q_runs} æ¬¡è¿è¡Œ")
            
            # æ€§èƒ½æƒè¡¡åˆ†æ
            if pd.notna(c_kl) and pd.notna(q_kl):
                efficiency_score = (c_kl - q_kl) / (q_time/c_time - 1)  # è´¨é‡æ”¹è¿› vs æ—¶é—´æˆæœ¬
                print(f"\næ€§èƒ½æƒè¡¡:")
                print(f"- æ—¶é—´æˆæœ¬: é‡å­ç”Ÿæˆå™¨æ…¢ {q_time/c_time:.1f}x")
                if q_kl < c_kl:
                    print(f"- è´¨é‡æ”¶ç›Š: KLæ•£åº¦æ”¹å–„ {(c_kl-q_kl)/c_kl*100:.1f}%")
                    if efficiency_score > 0:
                        print(f"- ç»“è®º: è´¨é‡æ”¹è¿›è¯æ˜æ—¶é—´æˆæœ¬æ˜¯åˆç†çš„")
                    else:
                        print(f"- ç»“è®º: è´¨é‡æ”¹è¿›ç›¸å¯¹äºæ—¶é—´æˆæœ¬è¾ƒå°")
                else:
                    print(f"- è´¨é‡æŸå¤±: KLæ•£åº¦æ¶åŒ– {(q_kl-c_kl)/c_kl*100:.1f}%")
                    print(f"- ç»“è®º: é‡å­ç”Ÿæˆå™¨åœ¨å½“å‰é…ç½®ä¸‹æ€§èƒ½ä¸å¦‚å¤å…¸ç”Ÿæˆå™¨")
            
            print("\nğŸ“‹ å®éªŒå»ºè®®:")
            print("- è€ƒè™‘ä¼˜åŒ–é‡å­ç”µè·¯å‚æ•°ä»¥æé«˜è®­ç»ƒæ•ˆç‡")
            print("- å¢åŠ é‡å­ç”Ÿæˆå™¨çš„è®­ç»ƒepochsä»¥è·å¾—æ›´å¥½çš„æ”¶æ•›")
            print("- å°è¯•ä¸åŒçš„é‡å­ç”µè·¯æ¶æ„")