#!/usr/bin/env python
"""
é‡å­vså¤å…¸ç”Ÿæˆå™¨æ€§èƒ½å¯¹æ¯”åˆ†æè„šæœ¬ (FIXED VERSION)
ç”¨äºæ¯”è¾ƒä¸åŒç”Ÿæˆå™¨ç±»å‹çš„æ€§èƒ½æŒ‡æ ‡

ä¿®å¤çš„é—®é¢˜:
1. å¯è§†åŒ–æ•°ç»„ç´¢å¼•é”™è¯¯
2. æ·»åŠ MLflowé”™è¯¯å¤„ç†
3. å¢åŠ æŒ‡æ ‡éªŒè¯
4. æ”¹è¿›é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
"""

import mlflow
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional
import warnings
import logging
import os
from pathlib import Path

warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_experiment_runs(experiment_name: str, max_runs: int = 1000) -> pd.DataFrame:
    """è·å–å®éªŒçš„æ‰€æœ‰è¿è¡Œè®°å½•
    
    Args:
        experiment_name: å®éªŒåç§°
        max_runs: æœ€å¤§è¿”å›è¿è¡Œæ•°é‡ï¼Œé˜²æ­¢å†…å­˜é—®é¢˜
    
    Returns:
        åŒ…å«è¿è¡Œæ•°æ®çš„DataFrame
    """
    try:
        client = mlflow.tracking.MlflowClient()
        experiment = client.get_experiment_by_name(experiment_name)
        
        if experiment is None:
            logger.warning(f"å®éªŒ '{experiment_name}' ä¸å­˜åœ¨")
            return pd.DataFrame()
        
        runs = client.search_runs(
            experiment_ids=[experiment.experiment_id],
            order_by=["attribute.start_time desc"],
            max_results=max_runs
        )
        
        if not runs:
            logger.warning(f"å®éªŒ '{experiment_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°è¿è¡Œè®°å½•")
            return pd.DataFrame()
        
        # æå–è¿è¡Œæ•°æ®
        data = []
        for run in runs:
            run_data = {
                'run_id': run.info.run_id,
                'generator_type': run.data.params.get('generator_type', 'unknown'),
                'status': run.info.status,
                'start_time': run.info.start_time,
                'end_time': run.info.end_time,
                'duration_seconds': (run.info.end_time - run.info.start_time) / 1000 if run.info.end_time else None
            }
            
            # æ·»åŠ å…³é”®æŒ‡æ ‡
            metrics_to_track = [
                'ValidationStep_FakeData_KLDivergence',
                'ValidationStep_FakeData_LogLikelihood', 
                'ValidationStep_FakeData_IsPositive',
                'ValidationStep_FakeData_WassersteinDistance',
                'ValidationStep_FakeData_MMDDistance',
                'train_loss_step',
                'd_loss',
                'g_loss'
            ]
            
            for metric in metrics_to_track:
                run_data[metric] = run.data.metrics.get(metric, None)
            
            data.append(run_data)
        
        df = pd.DataFrame(data)
        logger.info(f"æˆåŠŸè·å– {len(df)} æ¡è¿è¡Œè®°å½•")
        return df
        
    except Exception as e:
        logger.error(f"è·å–å®éªŒè¿è¡Œè®°å½•å¤±è´¥: {e}")
        return pd.DataFrame()

def validate_metrics(gen_runs: pd.DataFrame, gen_type: str) -> bool:
    """éªŒè¯å…³é”®æŒ‡æ ‡æ˜¯å¦å­˜åœ¨å’Œæœ‰æ•ˆ
    
    Args:
        gen_runs: ç”Ÿæˆå™¨è¿è¡Œæ•°æ®
        gen_type: ç”Ÿæˆå™¨ç±»å‹
    
    Returns:
        éªŒè¯æ˜¯å¦é€šè¿‡
    """
    required_metrics = [
        'ValidationStep_FakeData_KLDivergence',
        'duration_seconds'
    ]
    
    issues = []
    for metric in required_metrics:
        if metric not in gen_runs.columns:
            issues.append(f"ç¼ºå°‘æŒ‡æ ‡åˆ— {metric}")
        elif gen_runs[metric].isna().all():
            issues.append(f"æŒ‡æ ‡ {metric} å…¨éƒ¨ä¸ºç©ºå€¼")
        elif gen_runs[metric].notna().sum() == 0:
            issues.append(f"æŒ‡æ ‡ {metric} æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
    
    if issues:
        logger.warning(f"ç”Ÿæˆå™¨ {gen_type} æ•°æ®éªŒè¯å¤±è´¥: {'; '.join(issues)}")
        return False
    
    return True

def analyze_convergence(client, run_id: str) -> Dict:
    """åˆ†æå•ä¸ªè¿è¡Œçš„æ”¶æ•›ç‰¹æ€§
    
    Args:
        client: MLflowå®¢æˆ·ç«¯
        run_id: è¿è¡ŒID
    
    Returns:
        æ”¶æ•›åˆ†æç»“æœå­—å…¸
    """
    try:
        # è·å–å†å²æŒ‡æ ‡
        metric_history = client.get_metric_history(run_id, "ValidationStep_FakeData_KLDivergence")
        
        if not metric_history:
            logger.warning(f"è¿è¡Œ {run_id} æ²¡æœ‰KLæ•£åº¦å†å²æ•°æ®")
            return {}
        
        epochs = [m.step for m in metric_history]
        values = [m.value for m in metric_history]
        
        if not values:
            return {}
        
        # è®¡ç®—æ”¶æ•›æŒ‡æ ‡
        convergence_info = {
            'final_value': values[-1],
            'best_value': min(values),
            'epochs_to_best': epochs[np.argmin(values)],
            'improvement_rate': (values[0] - values[-1]) / len(values) if len(values) > 1 else 0,
            'stability': np.std(values[-5:]) if len(values) >= 5 else None
        }
        
        return convergence_info
        
    except Exception as e:
        logger.error(f"åˆ†æè¿è¡Œ {run_id} æ”¶æ•›æ€§å¤±è´¥: {e}")
        return {}

def safe_calculate_percentage_diff(val1: float, val2: float) -> Optional[float]:
    """å®‰å…¨è®¡ç®—ç™¾åˆ†æ¯”å·®å¼‚
    
    Args:
        val1: åŸºå‡†å€¼
        val2: æ¯”è¾ƒå€¼
    
    Returns:
        ç™¾åˆ†æ¯”å·®å¼‚ï¼Œå¦‚æœè®¡ç®—å¤±è´¥è¿”å›None
    """
    try:
        if pd.isna(val1) or pd.isna(val2):
            return None
        if val1 == 0:
            return float('inf') if val2 != 0 else 0
        return ((val2 - val1) / val1 * 100)
    except Exception:
        return None

def compare_generators(experiment_name: str = "quantum_vs_classical_comparison", 
                      output_dir: str = ".") -> Optional[pd.DataFrame]:
    """ä¸»å¯¹æ¯”å‡½æ•°
    
    Args:
        experiment_name: å®éªŒåç§°
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        å¯¹æ¯”ç»“æœDataFrameï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    print("=" * 80)
    print("é‡å­ vs å¤å…¸ç”Ÿæˆå™¨æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è·å–è¿è¡Œæ•°æ®
    df = get_experiment_runs(experiment_name)
    
    if df.empty:
        logger.error("æ²¡æœ‰æ‰¾åˆ°å®éªŒæ•°æ®ï¼Œè¯·å…ˆè¿è¡Œå®éªŒ")
        return None
    
    # æŒ‰ç”Ÿæˆå™¨ç±»å‹åˆ†ç»„
    generator_types = df['generator_type'].unique()
    print(f"\næ‰¾åˆ° {len(generator_types)} ç§ç”Ÿæˆå™¨ç±»å‹: {list(generator_types)}")
    print(f"æ€»å…± {len(df)} æ¬¡è¿è¡Œ\n")
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    comparison_results = []
    
    try:
        client = mlflow.tracking.MlflowClient()
        
        for gen_type in generator_types:
            gen_runs = df[df['generator_type'] == gen_type]
            
            # éªŒè¯æ•°æ®è´¨é‡
            if not validate_metrics(gen_runs, gen_type):
                logger.warning(f"è·³è¿‡ç”Ÿæˆå™¨ç±»å‹ {gen_type} ç”±äºæ•°æ®è´¨é‡é—®é¢˜")
                continue
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡ï¼ˆåªä½¿ç”¨æœ‰æ•ˆæ•°æ®ï¼‰
            result = {
                'ç”Ÿæˆå™¨ç±»å‹': gen_type,
                'è¿è¡Œæ¬¡æ•°': len(gen_runs),
                'å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)': gen_runs['duration_seconds'].mean(),
                'KLæ•£åº¦(å¹³å‡)': gen_runs['ValidationStep_FakeData_KLDivergence'].mean(),
                'KLæ•£åº¦(æœ€ä½³)': gen_runs['ValidationStep_FakeData_KLDivergence'].min(),
                'å¯¹æ•°ä¼¼ç„¶(å¹³å‡)': gen_runs['ValidationStep_FakeData_LogLikelihood'].mean(),
                'Wassersteinè·ç¦»': gen_runs['ValidationStep_FakeData_WassersteinDistance'].mean(),
                'MMDè·ç¦»': gen_runs['ValidationStep_FakeData_MMDDistance'].mean(),
            }
            
            # è·å–æœ€ä½³è¿è¡Œçš„æ”¶æ•›ä¿¡æ¯
            valid_kl_runs = gen_runs.dropna(subset=['ValidationStep_FakeData_KLDivergence'])
            if not valid_kl_runs.empty:
                best_run = valid_kl_runs.nsmallest(1, 'ValidationStep_FakeData_KLDivergence').iloc[0]
                convergence = analyze_convergence(client, best_run['run_id'])
                result.update({
                    'æ”¶æ•›epochs': convergence.get('epochs_to_best', 'N/A'),
                    'æ”¹è¿›ç‡': convergence.get('improvement_rate', 'N/A'),
                    'æœ€ç»ˆç¨³å®šæ€§': convergence.get('stability', 'N/A')
                })
            else:
                result.update({
                    'æ”¶æ•›epochs': 'N/A',
                    'æ”¹è¿›ç‡': 'N/A',
                    'æœ€ç»ˆç¨³å®šæ€§': 'N/A'
                })
            
            comparison_results.append(result)
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå™¨å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        return None
    
    if not comparison_results:
        logger.error("æ²¡æœ‰æœ‰æ•ˆçš„å¯¹æ¯”ç»“æœ")
        return None
    
    # åˆ›å»ºå¯¹æ¯”DataFrame
    comparison_df = pd.DataFrame(comparison_results)
    
    # æ‰“å°è¯¦ç»†å¯¹æ¯”
    print("\n" + "="*80)
    print("æ€§èƒ½å¯¹æ¯”ç»“æœ")
    print("="*80)
    
    # è®­ç»ƒæ•ˆç‡å¯¹æ¯”
    print("\nğŸ“Š è®­ç»ƒæ•ˆç‡å¯¹æ¯”:")
    print("-" * 40)
    for _, row in comparison_df.iterrows():
        duration = row['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)']
        if pd.notna(duration):
            print(f"{row['ç”Ÿæˆå™¨ç±»å‹']:20s}: {duration:.2f} ç§’")
        else:
            print(f"{row['ç”Ÿæˆå™¨ç±»å‹']:20s}: N/A")
    
    # ç”Ÿæˆè´¨é‡å¯¹æ¯”
    print("\nğŸ“ˆ ç”Ÿæˆè´¨é‡å¯¹æ¯” (è¶Šä½è¶Šå¥½):")
    print("-" * 40)
    print(f"{'æŒ‡æ ‡':<20} {'å¤å…¸ç”Ÿæˆå™¨':<15} {'é‡å­ç”Ÿæˆå™¨':<15} {'å·®å¼‚':<15}")
    print("-" * 65)
    
    metrics_to_compare = ['KLæ•£åº¦(æœ€ä½³)', 'Wassersteinè·ç¦»', 'MMDè·ç¦»']
    
    for metric in metrics_to_compare:
        classical_val = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('classical', na=False)][metric].values
        quantum_val = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('quantum', na=False)][metric].values
        
        if len(classical_val) > 0 and len(quantum_val) > 0:
            c_val = classical_val[0]
            q_val = quantum_val[0]
            diff = safe_calculate_percentage_diff(c_val, q_val)
            
            c_str = f"{c_val:.4f}" if pd.notna(c_val) else "N/A"
            q_str = f"{q_val:.4f}" if pd.notna(q_val) else "N/A"
            diff_str = f"{diff:+.1f}%" if diff is not None else "N/A"
            
            print(f"{metric:<20} {c_str:<15} {q_str:<15} {diff_str}")
    
    # æ”¶æ•›é€Ÿåº¦å¯¹æ¯”
    print("\nâš¡ æ”¶æ•›é€Ÿåº¦å¯¹æ¯”:")
    print("-" * 40)
    for _, row in comparison_df.iterrows():
        print(f"{row['ç”Ÿæˆå™¨ç±»å‹']:20s}: {row['æ”¶æ•›epochs']} epochs")
    
    # æ€§èƒ½æ¯”ç‡è®¡ç®—
    print("\n" + "="*80)
    print("æ€§èƒ½æ¯”ç‡åˆ†æ")
    print("="*80)
    
    classical_time = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('classical', na=False)]['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].values
    quantum_time = comparison_df[comparison_df['ç”Ÿæˆå™¨ç±»å‹'].str.contains('quantum', na=False)]['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].values
    
    if len(classical_time) > 0 and len(quantum_time) > 0:
        c_time, q_time = classical_time[0], quantum_time[0]
        if pd.notna(c_time) and pd.notna(q_time) and c_time > 0:
            time_ratio = q_time / c_time
            print(f"\nâ±ï¸  æ—¶é—´æ¯”ç‡: é‡å­ç”Ÿæˆå™¨æ¯”å¤å…¸ç”Ÿæˆå™¨æ…¢ {time_ratio:.1f}x")
        else:
            print("\nâ±ï¸  æ—¶é—´æ¯”ç‡: æ— æ³•è®¡ç®—ï¼ˆæ•°æ®ä¸å®Œæ•´ï¼‰")
    
    # åˆ›å»ºå¯è§†åŒ–
    try:
        create_visualization(comparison_df, output_path)
    except Exception as e:
        logger.error(f"å¯è§†åŒ–åˆ›å»ºå¤±è´¥: {e}")
    
    # ä¿å­˜ç»“æœ
    try:
        csv_path = output_path / 'generator_comparison_results.csv'
        comparison_df.to_csv(csv_path, index=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
    except Exception as e:
        logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
    
    return comparison_df

def create_visualization(comparison_df: pd.DataFrame, output_path: Path):
    """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨
    
    Args:
        comparison_df: å¯¹æ¯”æ•°æ®DataFrame
        output_path: è¾“å‡ºè·¯å¾„
    """
    try:
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # è®­ç»ƒæ—¶é—´å¯¹æ¯” - ä¿®å¤æ•°ç»„ç´¢å¼•
        ax = axes[0][0]  # ä¿®å¤: ä» axes[0, 0] æ”¹ä¸º axes[0][0]
        valid_data = comparison_df.dropna(subset=['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'])
        if not valid_data.empty:
            ax.bar(valid_data['ç”Ÿæˆå™¨ç±»å‹'], valid_data['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'])
        ax.set_title('è®­ç»ƒæ—¶é—´å¯¹æ¯”')
        ax.set_ylabel('æ—¶é—´ (ç§’)')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        ax.tick_params(axis='x', rotation=45)
        
        # KLæ•£åº¦å¯¹æ¯” - ä¿®å¤æ•°ç»„ç´¢å¼•
        ax = axes[0][1]  # ä¿®å¤: ä» axes[0, 1] æ”¹ä¸º axes[0][1]
        valid_data = comparison_df.dropna(subset=['KLæ•£åº¦(æœ€ä½³)'])
        if not valid_data.empty:
            ax.bar(valid_data['ç”Ÿæˆå™¨ç±»å‹'], valid_data['KLæ•£åº¦(æœ€ä½³)'])
        ax.set_title('KLæ•£åº¦å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        ax.set_ylabel('KLæ•£åº¦')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        ax.tick_params(axis='x', rotation=45)
        
        # Wassersteinè·ç¦»å¯¹æ¯” - ä¿®å¤æ•°ç»„ç´¢å¼•
        ax = axes[1][0]  # ä¿®å¤: ä» axes[1, 0] æ”¹ä¸º axes[1][0]
        valid_data = comparison_df.dropna(subset=['Wassersteinè·ç¦»'])
        if not valid_data.empty:
            ax.bar(valid_data['ç”Ÿæˆå™¨ç±»å‹'], valid_data['Wassersteinè·ç¦»'])
        ax.set_title('Wassersteinè·ç¦»å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        ax.set_ylabel('Wassersteinè·ç¦»')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        ax.tick_params(axis='x', rotation=45)
        
        # MMDè·ç¦»å¯¹æ¯” - ä¿®å¤æ•°ç»„ç´¢å¼•
        ax = axes[1][1]  # ä¿®å¤: ä» axes[1, 1] æ”¹ä¸º axes[1][1]
        valid_data = comparison_df.dropna(subset=['MMDè·ç¦»'])
        if not valid_data.empty:
            ax.bar(valid_data['ç”Ÿæˆå™¨ç±»å‹'], valid_data['MMDè·ç¦»'])
        ax.set_title('MMDè·ç¦»å¯¹æ¯” (è¶Šä½è¶Šå¥½)')
        ax.set_ylabel('MMDè·ç¦»')
        ax.set_xlabel('ç”Ÿæˆå™¨ç±»å‹')
        ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        png_path = output_path / 'generator_comparison_plots.png'
        plt.savefig(png_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {png_path}")
        
        # æ¸…ç†matplotlibèµ„æº
        plt.close()
        
    except Exception as e:
        logger.error(f"åˆ›å»ºå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        if 'fig' in locals():
            plt.close()

if __name__ == "__main__":
    # è¿è¡Œå¯¹æ¯”åˆ†æ
    try:
        results = compare_generators()
        
        if results is not None and not results.empty:
            print("\n" + "="*80)
            print("ğŸ¯ å…³é”®å‘ç°:")
            print("="*80)
            
            # è®¡ç®—å…³é”®æŒ‡æ ‡
            classical_rows = results[results['ç”Ÿæˆå™¨ç±»å‹'].str.contains('classical', na=False)]
            quantum_rows = results[results['ç”Ÿæˆå™¨ç±»å‹'].str.contains('quantum', na=False)]
            
            if not classical_rows.empty and not quantum_rows.empty:
                c_kl = classical_rows['KLæ•£åº¦(æœ€ä½³)'].values[0]
                q_kl = quantum_rows['KLæ•£åº¦(æœ€ä½³)'].values[0]
                c_time = classical_rows['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].values[0]
                q_time = quantum_rows['å¹³å‡è®­ç»ƒæ—¶é—´(ç§’)'].values[0]
                
                if pd.notna(c_time) and pd.notna(q_time) and c_time > 0:
                    print(f"\n1. é‡å­ç”Ÿæˆå™¨è®­ç»ƒæ—¶é—´æ˜¯å¤å…¸ç”Ÿæˆå™¨çš„ {q_time/c_time:.1f} å€")
                
                if pd.notna(c_kl) and pd.notna(q_kl):
                    if q_kl < c_kl:
                        print(f"2. é‡å­ç”Ÿæˆå™¨çš„KLæ•£åº¦æ¯”å¤å…¸ç”Ÿæˆå™¨ä½ {(c_kl-q_kl)/c_kl*100:.1f}% (æ›´å¥½)")
                    else:
                        print(f"2. é‡å­ç”Ÿæˆå™¨çš„KLæ•£åº¦æ¯”å¤å…¸ç”Ÿæˆå™¨é«˜ {(q_kl-c_kl)/c_kl*100:.1f}% (æ›´å·®)")
                
                print("\nè¿™äº›æ•°å€¼åŒ–ç»“æœç›´æ¥å›ç­”äº†Aleçš„é—®é¢˜ï¼š")
                print("âœ… æˆ‘ä»¬ç°åœ¨å¯ä»¥ç²¾ç¡®æµ‹é‡å¤å…¸å’Œé‡å­ç”Ÿæˆå™¨çš„æ€§èƒ½å·®å¼‚")
                print("âœ… ä¸ä»…æœ‰å¯è§†åŒ–å¯¹æ¯”ï¼Œè¿˜æœ‰å…·ä½“çš„æ•°å€¼æŒ‡æ ‡")
            else:
                print("æœªæ‰¾åˆ°è¶³å¤Ÿçš„å¤å…¸å’Œé‡å­ç”Ÿæˆå™¨æ•°æ®è¿›è¡Œå¯¹æ¯”")
        else:
            print("å¯¹æ¯”åˆ†æå¤±è´¥æˆ–æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print("ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")