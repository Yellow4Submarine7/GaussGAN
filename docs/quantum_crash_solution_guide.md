# GaussGAN Quantum_Samples ç³»ç»Ÿå´©æºƒè§£å†³æ–¹æ¡ˆ

## ğŸš¨ å´©æºƒåŸå› æ€»ç»“

### ä¸»è¦é—®é¢˜
1. **å†…å­˜çˆ†ç‚¸**: `batch_size=256` + é‡å­ç”µè·¯ = ç³»ç»Ÿçº§OOM
2. **è®¾å¤‡æ³„æ¼**: æ¯ä¸ªQuantumNoiseå®ä¾‹åˆ›å»ºç‹¬ç«‹é‡å­è®¾å¤‡
3. **çº¿ç¨‹ç«äº‰**: éçº¿ç¨‹å®‰å…¨çš„éšæœºæ•°ç”Ÿæˆ
4. **CUDAç¢ç‰‡åŒ–**: PennyLaneä¸å¤§æ‰¹é‡CUDAå†…å­˜ç®¡ç†å†²çª

### å´©æºƒè¯æ®
- MLflowæ—¥å¿—æ˜¾ç¤ºquantum_samplesè¿è¡Œä»…å®Œæˆ1ä¸ªepoch
- ç³»ç»Ÿå†…å­˜å……è¶³(15GB)ä½†GPUå†…å­˜æœ‰é™(8GB RTX 4060)
- æ— ç³»ç»Ÿçº§é”™è¯¯æ—¥å¿—ï¼Œè¯´æ˜æ˜¯è½¯ä»¶å±‚é¢å†…å­˜é—®é¢˜

## âœ… ç«‹å³å¯ç”¨çš„è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: ç´§æ€¥é…ç½®ä¿®å¤ (æœ€å¿«é€Ÿ)

**ä½¿ç”¨å®‰å…¨é…ç½®æ–‡ä»¶:**
```bash
# å¤åˆ¶å®‰å…¨é…ç½®
cp /home/paperx/quantum/GaussGAN/docs/config_quantum_safe.yaml /home/paperx/quantum/GaussGAN/config_quantum_safe.yaml

# ä½¿ç”¨å®‰å…¨é…ç½®è¿è¡Œ
uv run python main.py --generator_type quantum_samples --max_epochs 20 --config config_quantum_safe.yaml
```

**å…³é”®å‚æ•°è°ƒæ•´:**
- `batch_size: 16` (ä»256é™ä½16å€!)
- `quantum_qubits: 4` (ä»6é™ä½ï¼Œå‡å°‘75%é‡å­æ€ç©ºé—´)
- `quantum_shots: 50` (ä»100é™ä½)
- `validation_samples: 200` (ä»500é™ä½)

### æ–¹æ¡ˆ2: ä»£ç çº§ä¿®å¤ (æ›´å½»åº•)

**ä¿®å¤QuantumNoiseç±»:**
```python
# ä½¿ç”¨ä¿®å¤åçš„é‡å­å™ªå£°ç±»
from docs.quantum_noise_fixed import QuantumNoiseFixed

# åœ¨main.pyä¸­æ›¿æ¢
if cfg['generator_type'] == 'quantum_samples':
    noise_generator = QuantumNoiseFixed(
        num_qubits=cfg['quantum_qubits'], 
        num_layers=cfg['quantum_layers']
    )
```

### æ–¹æ¡ˆ3: ç¯å¢ƒå…¼å®¹æ€§æ£€æŸ¥

**è¿è¡Œå…¼å®¹æ€§æ£€æŸ¥:**
```bash
uv run python /home/paperx/quantum/GaussGAN/docs/check_pennylane_cuda_compatibility.py
```

è¿™å°†æ£€æŸ¥:
- PyTorch CUDAç¯å¢ƒ
- PennyLaneè®¾å¤‡å…¼å®¹æ€§  
- å†…å­˜ä½¿ç”¨æ¨¡å¼
- æ‰¹å¤„ç†ç¨³å®šæ€§

## ğŸ›¡ï¸ é¢„é˜²æªæ–½

### 1. å†…å­˜ç›‘æ§
```python
def monitor_memory():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        print(f"GPUå†…å­˜: å·²åˆ†é…={allocated:.2f}GB, ç¼“å­˜={cached:.2f}GB")
        
        if allocated > 6.0:  # RTX 4060 8GBçš„75%
            torch.cuda.empty_cache()
            return True
    return False
```

### 2. æ¸è¿›å¼æ‰¹å¤§å°æµ‹è¯•
```bash
# æµ‹è¯•åºåˆ—: ä»å°åˆ°å¤§
for batch_size in 8 16 32 64; do
    echo "æµ‹è¯•æ‰¹å¤§å°: $batch_size"
    timeout 300 uv run python main.py --generator_type quantum_samples --max_epochs 5 --batch_size $batch_size
    if [ $? -eq 0 ]; then
        echo "æ‰¹å¤§å° $batch_size æˆåŠŸ"
    else
        echo "æ‰¹å¤§å° $batch_size å¤±è´¥"
        break
    fi
done
```

### 3. é‡å­å‚æ•°è°ƒä¼˜ç­–ç•¥
```yaml
# ä¿å®ˆé…ç½® (4GB GPU)
quantum_qubits: 3
quantum_layers: 1
batch_size: 8

# ä¸­ç­‰é…ç½® (8GB GPU) - æ¨è
quantum_qubits: 4  
quantum_layers: 2
batch_size: 16

# é«˜æ€§èƒ½é…ç½® (16GB+ GPU)
quantum_qubits: 6
quantum_layers: 3
batch_size: 32
```

## ğŸ” æ•…éšœæ’é™¤æµç¨‹

### Step 1: ç¯å¢ƒæ£€æŸ¥
```bash
# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi
free -h

# æ£€æŸ¥Pythonç¯å¢ƒ
uv pip list | grep -E "(torch|pennylane)"
```

### Step 2: æœ€å°åŒ–æµ‹è¯•
```bash
# ä½¿ç”¨æœ€å°é…ç½®æµ‹è¯•
uv run python -c "
from source.nn import QuantumNoise
import torch
qn = QuantumNoise(num_qubits=2, num_layers=1)
print('åˆ›å»ºæˆåŠŸ')
samples = qn(4)  # å°æ‰¹é‡
print(f'æ ·æœ¬å½¢çŠ¶: {samples.shape}')
"
```

### Step 3: é€æ­¥å¢åŠ å¤æ‚åº¦
1. å…ˆæµ‹è¯• `batch_size=4, qubits=2`
2. ç„¶åæµ‹è¯• `batch_size=8, qubits=3` 
3. æœ€åæµ‹è¯• `batch_size=16, qubits=4`

### Step 4: ç›‘æ§èµ„æºä½¿ç”¨
```bash
# è¿è¡Œæ—¶ç›‘æ§
watch -n 1 'nvidia-smi; echo "---"; free -h'
```

## âš ï¸ å·²çŸ¥é™åˆ¶å’Œå»ºè®®

### ç¡¬ä»¶é™åˆ¶ (RTX 4060 8GB)
- **å»ºè®®æœ€å¤§batch_size**: 16-32
- **å»ºè®®æœ€å¤§qubits**: 4-5
- **å»ºè®®æœ€å¤§layers**: 2-3

### PennyLane 0.42.2 æ³¨æ„äº‹é¡¹
- `default.qubit`è®¾å¤‡åœ¨å¤§æ‰¹é‡æ—¶å†…å­˜æ•ˆç‡è¾ƒä½
- è€ƒè™‘å‡çº§åˆ°æ›´æ–°ç‰ˆæœ¬æˆ–ä½¿ç”¨Lightning
- é¿å…é¢‘ç¹åˆ›å»º/é”€æ¯é‡å­è®¾å¤‡

### ç›‘æ§å’Œè°ƒè¯•
```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ 
import psutil
import GPUtil

def log_resources():
    # CPUå’Œå†…å­˜
    cpu_percent = psutil.cpu_percent()
    memory_info = psutil.virtual_memory()
    
    # GPU (å¦‚æœå¯ç”¨)
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3
        print(f"èµ„æºä½¿ç”¨: CPU={cpu_percent}%, RAM={memory_info.percent}%, GPU_MEM={gpu_memory:.2f}GB")
```

## ğŸ“‹ æµ‹è¯•æ¸…å•

åœ¨æ­£å¼è¿è¡Œå‰ï¼Œè¯·ç¡®è®¤:

- [ ] ä½¿ç”¨å®‰å…¨é…ç½®æ–‡ä»¶ (`config_quantum_safe.yaml`)
- [ ] batch_size <= 32
- [ ] quantum_qubits <= 4  
- [ ] è¿è¡Œäº†å…¼å®¹æ€§æ£€æŸ¥è„šæœ¬
- [ ] ç›‘æ§äº†å‰å‡ ä¸ªepochçš„å†…å­˜ä½¿ç”¨
- [ ] å‡†å¤‡äº†ç»ˆæ­¢å‘½ä»¤ (`Ctrl+C`)
- [ ] ç³»ç»Ÿæœ‰è¶³å¤Ÿçš„è™šæ‹Ÿå†…å­˜ (4GB+)

## ğŸ†˜ ç´§æ€¥å¤„ç†

å¦‚æœå†æ¬¡å‘ç”Ÿå´©æºƒ:

1. **ç«‹å³ç»ˆæ­¢**: `Ctrl+C` æˆ– `kill -9 <pid>`
2. **æ¸…ç†GPUå†…å­˜**: `nvidia-smi --gpu-reset` (å¦‚æœéœ€è¦)
3. **æ£€æŸ¥åƒµå°¸è¿›ç¨‹**: `ps aux | grep python`
4. **é‡å¯Pythonç¯å¢ƒ**: å…³é—­æ‰€æœ‰Pythonè¿›ç¨‹
5. **ä½¿ç”¨æ›´ä¿å®ˆçš„é…ç½®**: batch_size=8, qubits=3

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨:
1. æ”¶é›†å®Œæ•´çš„é”™è¯¯æ—¥å¿—
2. è¿è¡Œå…¼å®¹æ€§æ£€æŸ¥è„šæœ¬
3. è®°å½•ç³»ç»Ÿé…ç½®å’Œèµ„æºä½¿ç”¨æƒ…å†µ
4. è€ƒè™‘ä½¿ç”¨Classical generatorsä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ

---

**æœ€åæ›´æ–°**: 2025-08-22  
**æµ‹è¯•ç¯å¢ƒ**: WSL2 Ubuntu + RTX 4060 8GB  
**PennyLaneç‰ˆæœ¬**: 0.42.2  
**PyTorchç‰ˆæœ¬**: 2.0+